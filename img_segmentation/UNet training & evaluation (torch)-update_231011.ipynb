{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6600353f",
   "metadata": {},
   "source": [
    "# 세포 전자현미경을 통한 세포 이미지의 segmentation w/UNET 학습 및 테스트\n",
    "* isbi 2012 EM (Electron Microscopy) dataset과 UNET을 이용한 segmentation.\n",
    "* 해당 jupyter 포함내용\n",
    "  * train, evaluation (single GPU or multi GPUs 선택가능)\n",
    "  * visualization sample\n",
    "  * output save & visualization\n",
    "  * jupyter tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e523408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter    # tensorboard pip 설치시 이용가능\n",
    "\n",
    "from model import UNet\n",
    "from dataset import *\n",
    "from util import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542e15f-497f-4984-b312-9eafee95d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 이름 체크(cuda:0에 연결된 그래픽 카드 기준)\n",
    "# print((torch.cuda.get_device_name(), device = 0)) # 'NVIDIA TITAN X (Pascal)'\n",
    "\n",
    "# 사용 가능 GPU 개수 체크\n",
    "# print(torch.cuda.device_count()) # 3\n",
    "\n",
    "\n",
    "# gpu_count = torch.cuda.device_count()\n",
    "\n",
    "# if gpu_count > 0:\n",
    "#     print(f\"현재 사용 가능한 GPU 수: {gpu_count}\")\n",
    "#     for i in range(gpu_count):\n",
    "#         # 각 GPU의 번호와 이름을 확인합니다.\n",
    "#         gpu_name = torch.cuda.get_device_name(i)\n",
    "#         print(f\"GPU {i}: {gpu_name}\")\n",
    "# else:\n",
    "#     print(\"사용 가능한 GPU가 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c13d9",
   "metadata": {},
   "source": [
    "## st1. Setting custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b33e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "batch_size = 5\n",
    "num_epoch = 60 # 300  \n",
    "\n",
    "data_dir = \"datasets\"\n",
    "ckpt_dir = \"out/checkpoint\"\n",
    "log_dir = \"out/log\"\n",
    "result_dir = \"out/result\"\n",
    "\n",
    "mode = \"train\"    # train or test\n",
    "train_continue = \"off\"\n",
    "use_gpu = True\n",
    "multi_gpu = True\n",
    "gpu_idx = \"0\"    # GPU 환경일 때 이용할 GPU설정 (GPU 환경 아닐 경우 사용안함)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d144722",
   "metadata": {},
   "source": [
    "## st2. environment setting & dataset loading\n",
    "* 231011 - gpu idx selecting issue\n",
    "* [CUDA_VISIBLE_DEVICES is not working 링크](https://discuss.pytorch.org/t/os-environ-cuda-visible-devices-not-functioning/105545/2) The CUDA_VISIBLE_DEVICES environment variable is read by the cuda driver. So it needs to be set before the cuda driver is initialized. It is best if you make sure it is set before importing torch (or at least before you do anything cuda related in torch).\n",
    "* 위의 이슈에 따르면 `CUDA_VISIBLE_DEVICES` 는 드라이버가 초기화 되면서 준비되는거기 때문에 드라이버가 인식되기 전에 미리 설정해야 하는 변수임. 따라서 `torch.cuda.is_available()` 이 먼저 나오면 안됌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4b7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## torch.cuda.is_available()이 먼저 드라이버가 인식이 되어서 gpu idx 설정이 불가함\n",
    "# if torch.cuda.is_available() and multi_gpu:\n",
    "#     # 아래 이걸 구성하면 한 jupyter에서 training, evaluation 진행이 불가함.\n",
    "#     os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "#     os.environ['CUDA_VISIBLE_DEVICES'] = gpu_idx\n",
    "\n",
    "\n",
    "if use_gpu:\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpu_idx\n",
    "\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(device)\n",
    "    \n",
    "print(\"learning rate: %.4e\" % lr)\n",
    "print(\"batch size: %d\" % batch_size)\n",
    "print(\"number of epoch: %d\" % num_epoch)\n",
    "print(\"data dir: %s\" % data_dir)\n",
    "print(\"ckpt dir: %s\" % ckpt_dir)\n",
    "print(\"log dir: %s\" % log_dir)\n",
    "print(\"result dir: %s\" % result_dir)\n",
    "\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset for training\n",
    "transform = transforms.Compose([Normalization(mean=0.5, std=0.5), RandomFlip(), ToTensor()])\n",
    "\n",
    "dataset_train = Dataset(data_dir=os.path.join(data_dir, 'train'), transform=transform)\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "dataset_val = Dataset(data_dir=os.path.join(data_dir, 'val'), transform=transform)\n",
    "loader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# 그밖에 부수적인 variables 설정하기\n",
    "# tensorboard외 loss 진행사항을 출력하기 위한 변수\n",
    "num_data_train = len(dataset_train)\n",
    "num_data_val = len(dataset_val)\n",
    "\n",
    "# batch로 인한 training 수를 확인하기 위한 변수\n",
    "num_batch_train = np.ceil(num_data_train / batch_size)\n",
    "num_batch_val = np.ceil(num_data_val / batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b059243e",
   "metadata": {},
   "source": [
    "### 2-1. dataset visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3944f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_imgnp_labelnp(img_tensor, label_tensor):\n",
    "    \"\"\"\n",
    "    img, label : tensor -> np & (C, H, W) -> (H, W, C) & sqeeze dim\n",
    "    img: + denormalizing\n",
    "    \"\"\"\n",
    "    \n",
    "    fn_tonumpy = lambda x: x.to('cpu').detach().numpy().transpose(1, 2, 0) # tensor to np & (c, h, w) -> (h, w, c)\n",
    "    fn_denorm = lambda x, mean, std: (x * std) + mean    # norm val -> denormalization\n",
    "\n",
    "    label = fn_tonumpy(label_tensor).squeeze()     # channel 삭제\n",
    "    input = fn_tonumpy(fn_denorm(img_tensor, mean=0.5, std=0.5)).squeeze()\n",
    "    \n",
    "    return input, label\n",
    "\n",
    "def draw_img_label(img_np, label_np, cmap='color', size=None, ratio=None, img_title=None, label_title=None):\n",
    "    # cmap에 따라 컬러 or 흑백 이미지 그림\n",
    "    %matplotlib inline\n",
    "    \n",
    "    if type(img_np) != np.ndarray:\n",
    "        img_np = read_img_to_np(img_np, cmap=cmap)\n",
    "        label_np = read_img_to_np(label_np, cmap=cmap)\n",
    "    \n",
    "    print(f\"input shape: {img_np.shape}\")\n",
    "    print(f\"label shape: {label_np.shape}\")\n",
    "    \n",
    "    if size:\n",
    "        plt.figure(figsize=size)\n",
    "    elif ratio:\n",
    "        plt.figure(figsize=(8*ratio, 8*ratio))\n",
    "    else:\n",
    "        plt.figure()\n",
    "    \n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.imshow(img_np, cmap=cmap)\n",
    "    if not img_title:\n",
    "        img_title = \"input\"\n",
    "    plt.title(img_title, fontsize=15)\n",
    "\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.imshow(label_np, cmap=cmap)\n",
    "    if not label_title:\n",
    "        label_title = \"label\"\n",
    "    plt.title(label_title, fontsize=15)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def draw_img_label_output(\n",
    "    img_np, label_np, output_np, cmap='color', size=None, ratio=None, \n",
    "    img_title=None, label_title=None, output_title=None\n",
    "):\n",
    "    # cmap에 따라 컬러 or 흑백 이미지 그림\n",
    "    %matplotlib inline\n",
    "    \n",
    "    if type(img_np) != np.ndarray:\n",
    "        img_np = read_img_to_np(img_np, cmap=cmap)\n",
    "        label_np = read_img_to_np(label_np, cmap=cmap)\n",
    "        output_np = read_img_to_np(output_np, cmap=cmap)\n",
    "    \n",
    "    print(f\"input shape: {img_np.shape}\")\n",
    "    print(f\"label shape: {label_np.shape}\")\n",
    "    print(f\"output shape: {output_np.shape}\")\n",
    "    \n",
    "    if size:\n",
    "        plt.figure(figsize=size)\n",
    "    elif ratio:\n",
    "        plt.figure(figsize=(8*ratio, 8*ratio))\n",
    "    else:\n",
    "        plt.figure()\n",
    "    \n",
    "    \n",
    "    plt.subplot(131)\n",
    "    plt.imshow(img_np, cmap=cmap)\n",
    "    if not img_title:\n",
    "        img_title = \"input\"\n",
    "    plt.title(img_title, fontsize=15)\n",
    "\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.imshow(label_np, cmap=cmap)\n",
    "    if not label_title:\n",
    "        label_title = \"label\"\n",
    "    plt.title(label_title, fontsize=15)\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    plt.imshow(output_np, cmap=cmap)\n",
    "    if not output_title:\n",
    "        output_title = \"output\"\n",
    "    plt.title(output_title, fontsize=15)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba6ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dataset_train))\n",
    "input, label = sample['input'], sample['label']\n",
    "input, label = tensor_to_imgnp_labelnp(input, label)\n",
    "draw_img_label(input, label, cmap='gray', size=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76d034",
   "metadata": {},
   "source": [
    "## st3. Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 네트워크 생성하기\n",
    "\n",
    "# multi gpu setting\n",
    "if torch.cuda.is_available() and multi_gpu:\n",
    "    net = UNet()\n",
    "    # net = nn.DataParallel(net).to(device)\n",
    "    net = nn.DataParallel(net)\n",
    "    net.cuda()\n",
    "else:\n",
    "    net = UNet().to(device)\n",
    "\n",
    "## 손실함수 정의하기 - binary classification\n",
    "fn_loss = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "## Optimizer 설정하기\n",
    "optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "## 그밖에 부수적인 functions 설정하기\n",
    "fn_tonumpy = lambda x: x.to('cpu').detach().numpy().transpose(0, 2, 3, 1) # tensor to np\n",
    "fn_denorm = lambda x, mean, std: (x * std) + mean    # norm val -> denormalization (tensorboard 적용)\n",
    "fn_class = lambda x: 1.0 * (x > 0.5)    # binary class로 변경(softmax 개념) (tensorboard 적용)\n",
    "\n",
    "## Tensorboard 를 사용하기 위한 SummaryWriter 설정\n",
    "writer_train = SummaryWriter(log_dir=os.path.join(log_dir, 'train'))\n",
    "writer_val = SummaryWriter(log_dir=os.path.join(log_dir, 'val'))\n",
    "\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b9246",
   "metadata": {},
   "source": [
    "## st4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = 2     # 1: all print / 2: epoch print / False: only time print\n",
    "\n",
    "\n",
    "st_epoch = 0\n",
    "epoch_time_list = list()\n",
    "\n",
    "if train_continue == \"on\":\n",
    "    # 특히 colab에서 session 재시작의 경우 문제가 생길 수 있으므로. 다음과 같이 설정\n",
    "    net, optim, st_epoch = load(ckpt_dir=ckpt_dir, net=net, optim=optim)\n",
    "\n",
    "for epoch in range(st_epoch + 1, num_epoch + 1):\n",
    "    net.train()\n",
    "    loss_arr = []\n",
    "\n",
    "    print('-------------- epoch {} ----------------'.format(epoch)) \n",
    "    since = time.time() \n",
    "    \n",
    "    for batch, data in enumerate(loader_train, 1):\n",
    "        # forward pass\n",
    "        label = data['label'].to(device)\n",
    "        input = data['input'].to(device)\n",
    "\n",
    "        output = net(input)\n",
    "\n",
    "        # backward pass\n",
    "        optim.zero_grad()\n",
    "\n",
    "        loss = fn_loss(output, label)\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "        # 손실함수 계산\n",
    "        # 내부 format 궁금하네\n",
    "        loss_arr += [loss.item()]\n",
    "\n",
    "        if VERBOSE == 1:\n",
    "            print(\"TRAIN: EPOCH %04d / %04d | BATCH %04d / %04d | LOSS %.4f\" %\n",
    "                  (epoch, num_epoch, batch, num_batch_train, np.mean(loss_arr)))\n",
    "\n",
    "        # Tensorboard 저장하기\n",
    "        label = fn_tonumpy(label)\n",
    "        input = fn_tonumpy(fn_denorm(input, mean=0.5, std=0.5))\n",
    "        output = fn_tonumpy(fn_class(output))\n",
    "\n",
    "        # Tensorboard 에 img를 저장\n",
    "        writer_train.add_image('label', label, num_batch_train * (epoch - 1) + batch, dataformats='NHWC')\n",
    "        writer_train.add_image('input', input, num_batch_train * (epoch - 1) + batch, dataformats='NHWC')\n",
    "        writer_train.add_image('output', output, num_batch_train * (epoch - 1) + batch, dataformats='NHWC')\n",
    "\n",
    "    # epoch당 Tensorboard에 loss 저장\n",
    "    writer_train.add_scalar('loss', np.mean(loss_arr), epoch)\n",
    "\n",
    "    # epoch당 validation 시작\n",
    "    with torch.no_grad():   # backpropa block\n",
    "        net.eval()          # network에 validation 명시\n",
    "        loss_arr_val = []\n",
    "\n",
    "        for batch, data in enumerate(loader_val, 1):\n",
    "            # forward pass\n",
    "            label = data['label'].to(device)\n",
    "            input = data['input'].to(device)\n",
    "\n",
    "            output = net(input)\n",
    "\n",
    "            # 손실함수 계산하기\n",
    "            loss = fn_loss(output, label)\n",
    "\n",
    "            loss_arr_val += [loss.item()]\n",
    "\n",
    "            if VERBOSE == 1:\n",
    "                print(\"VALID: EPOCH %04d / %04d | BATCH %04d / %04d | LOSS %.4f\" %\n",
    "                      (epoch, num_epoch, batch, num_batch_val, np.mean(loss_arr)))\n",
    "\n",
    "            # Tensorboard 저장하기\n",
    "            label = fn_tonumpy(label)\n",
    "            input = fn_tonumpy(fn_denorm(input, mean=0.5, std=0.5))\n",
    "            output = fn_tonumpy(fn_class(output))\n",
    "\n",
    "            writer_val.add_image('label', label, num_batch_val * (epoch - 1) + batch, dataformats='NHWC')\n",
    "            writer_val.add_image('input', input, num_batch_val * (epoch - 1) + batch, dataformats='NHWC')\n",
    "            writer_val.add_image('output', output, num_batch_val * (epoch - 1) + batch, dataformats='NHWC')\n",
    "\n",
    "    writer_val.add_scalar('loss', np.mean(loss_arr_val), epoch)\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(f\"EPOCH {epoch} / {num_epoch} | TRAIN mean.LOSS {np.mean(loss_arr):.3f}   VAL: mean.LOSS {np.mean(loss_arr_val):.3f}\")\n",
    "    \n",
    "    time_elapsed = time.time() - since  \n",
    "    print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    epoch_time_list.append(time_elapsed)\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        # 50 epoch당 모델 저장\n",
    "        save(ckpt_dir=ckpt_dir, net=net, optim=optim, epoch=epoch)\n",
    "\n",
    "# 학습 완료시 tensorboard closing\n",
    "writer_train.close()\n",
    "writer_val.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8174ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간 측정 테이블 저장\n",
    "\n",
    "time_result_dir = \"learning_time\"\n",
    "out_fname = 'time_exp3.csv'\n",
    "if not os.path.exists(time_result_dir):\n",
    "    os.makedirs(time_result_dir)\n",
    "\n",
    "df = pd.DataFrame(epoch_time_list, columns=[\"vanillaUNet_model\"])\n",
    "file_name = os.path.join(time_result_dir, out_fname)\n",
    "df.to_csv(file_name, index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc714591",
   "metadata": {},
   "source": [
    "## st5. Testing / Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cd57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## result dir 생성하기\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(os.path.join(result_dir, 'png'))\n",
    "    os.makedirs(os.path.join(result_dir, 'numpy'))\n",
    "\n",
    "# dataset for validation\n",
    "transform = transforms.Compose([Normalization(mean=0.5, std=0.5), ToTensor()])\n",
    "\n",
    "dataset_test = Dataset(data_dir=os.path.join(data_dir, 'test'), transform=transform)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# 그밖에 부수적인 variables 설정하기\n",
    "num_data_test = len(dataset_test)\n",
    "\n",
    "num_batch_test = np.ceil(num_data_test / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199a6819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(ckpt_dir, net, optim, cuda_idx=None):\n",
    "    print(\"!!!!!!!\")\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        # ckpt 없다면 기본 셋팅 return\n",
    "        epoch = 0\n",
    "        return net, optim, epoch\n",
    "\n",
    "    # ckpt있다면 학습 마지막 모델 load\n",
    "    ckpt_lst = os.listdir(ckpt_dir)\n",
    "    ckpt_lst.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "\n",
    "    if cuda_idx == None:\n",
    "        dict_model = torch.load('%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n",
    "    else:\n",
    "        dict_model = torch.load('%s/%s' % (ckpt_dir, ckpt_lst[-1]), map_location='cuda:0')\n",
    "\n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    optim.load_state_dict(dict_model['optim'])\n",
    "    epoch = int(ckpt_lst[-1].split('epoch')[1].split('.pth')[0])\n",
    "\n",
    "    return net, optim, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5007a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST MODE (맨 마지막 model을 불러와서 evaluation 진행)\n",
    "net, optim, st_epoch = load(ckpt_dir=ckpt_dir, net=net, optim=optim)\n",
    "\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    loss_arr = []\n",
    "\n",
    "    for batch, data in enumerate(loader_test, 1):\n",
    "        # forward pass\n",
    "        label = data['label'].to(device)\n",
    "        input = data['input'].to(device)\n",
    "\n",
    "        output = net(input)\n",
    "\n",
    "        # 손실함수 계산하기\n",
    "        loss = fn_loss(output, label)\n",
    "\n",
    "        loss_arr += [loss.item()]\n",
    "\n",
    "        print(\"TEST: BATCH %04d / %04d | LOSS %.4f\" %\n",
    "              (batch, num_batch_test, np.mean(loss_arr)))\n",
    "\n",
    "        # Tensorboard 저장하기\n",
    "        label = fn_tonumpy(label)\n",
    "        input = fn_tonumpy(fn_denorm(input, mean=0.5, std=0.5))\n",
    "        output = fn_tonumpy(fn_class(output))\n",
    "\n",
    "        for j in range(label.shape[0]):\n",
    "            id = num_batch_test * (batch - 1) + j\n",
    "\n",
    "            plt.imsave(os.path.join(result_dir, 'png', 'label_%04d.png' % id), label[j].squeeze(), cmap='gray')\n",
    "            plt.imsave(os.path.join(result_dir, 'png', 'input_%04d.png' % id), input[j].squeeze(), cmap='gray')\n",
    "            plt.imsave(os.path.join(result_dir, 'png', 'output_%04d.png' % id), output[j].squeeze(), cmap='gray')\n",
    "\n",
    "            np.save(os.path.join(result_dir, 'numpy', 'label_%04d.npy' % id), label[j].squeeze())\n",
    "            np.save(os.path.join(result_dir, 'numpy', 'input_%04d.npy' % id), input[j].squeeze())\n",
    "            np.save(os.path.join(result_dir, 'numpy', 'output_%04d.npy' % id), output[j].squeeze())\n",
    "\n",
    "print(\"AVERAGE TEST: BATCH %04d / %04d | LOSS %.4f\" %\n",
    "      (batch, num_batch_test, np.mean(loss_arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ddb71",
   "metadata": {},
   "source": [
    "### 5-1 dataset visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b56685",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dataset_test))\n",
    "input, label = sample['input'], sample['label']\n",
    "input = input.to(device).unsqueeze(dim=0)  # B dim add\n",
    "\n",
    "output = net(input)\n",
    "\n",
    "output = fn_tonumpy(fn_class(output))\n",
    "output = output.squeeze()\n",
    "input = input.squeeze(dim=0)\n",
    "\n",
    "input, label = tensor_to_imgnp_labelnp(input, label)\n",
    "draw_img_label_output(input, label, output, cmap='gray', size=(17, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b5600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "470bc8c6",
   "metadata": {},
   "source": [
    "# st 6. tensorboard check\n",
    "* train, validation 만 저장함\n",
    "\n",
    "## 6-1 이미지 수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ed9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_cnt = int(num_batch_train * num_epoch)\n",
    "val_img_cnt = int(num_batch_val * num_epoch)\n",
    "\n",
    "print(f\"train batch 수: {num_batch_train} / val batch 수: {num_batch_val}\")\n",
    "print(f\"loss 수: {num_epoch} epoch\")\n",
    "print(f\"tenboard train imgs : {train_img_cnt} 장 / tb val imgs : {val_img_cnt} 장\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0117b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce76d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tensorboard --host=0.0.0.0 --logdir='/data/kehyeong/project/youtube-cnn-002-pytorch-unet/out/log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05214b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1031fb4d",
   "metadata": {},
   "source": [
    "# st Opt. remove output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72596de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# out_dir = './out'\n",
    "# shutil.rmtree(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eac246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
